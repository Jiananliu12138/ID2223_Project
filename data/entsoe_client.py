"""
ENTSO-E data client
"""
from entsoe import EntsoePandasClient
import pandas as pd
from datetime import datetime, timedelta
from config.settings import ENTSOE_API_KEY, BIDDING_ZONE, TIMEZONE
import time
from tenacity import retry, wait_exponential, stop_after_attempt
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ENTSOEClient:
    """ENTSO-E Transparency Platform data client"""
    
    def __init__(self, api_key: str = None):
        """
        Initialize the ENTSO-E client
        
        Args:
            api_key: ENTSO-E API key. If not provided, read from environment/config
        """
        self.api_key = api_key or ENTSOE_API_KEY
        if not self.api_key:
            raise ValueError("ENTSO-E API keyæœªè®¾ç½®,è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®ENTSOE_API_KEY")
        
        self.client = EntsoePandasClient(api_key=self.api_key)
        self.bidding_zone = BIDDING_ZONE
        
    def _fetch_prices_raw_api(self, start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:
        """
        ç›´æ¥è°ƒç”¨ ENTSO-E REST APIï¼Œç»•è¿‡ entsoe-py çš„è§£æ bug
        """
        import requests
        from xml.etree import ElementTree as ET
        
        # ENTSO-E API endpoint
        url = "https://web-api.tp.entsoe.eu/api"
        
        # API parameters
        params = {
            'securityToken': self.api_key,
            'documentType': 'A44',  # Price document
            'in_Domain': self.bidding_zone,
            'out_Domain': self.bidding_zone,
            'periodStart': start.strftime('%Y%m%d%H%M'),
            'periodEnd': end.strftime('%Y%m%d%H%M')
        }
        
        logger.info(f"  ç›´æ¥è°ƒç”¨ ENTSO-E REST API...")
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
        
        # Parse XML
        root = ET.fromstring(response.content)
        
        # Extract time series data
        ns = {'ns': 'urn:iec62325.351:tc57wg16:451-3:publicationdocument:7:3'}
        
        timestamps = []
        prices = []
        
        for timeseries in root.findall('.//ns:TimeSeries', ns):
            for period in timeseries.findall('.//ns:Period', ns):
                # Get period start time
                start_time_str = period.find('ns:timeInterval/ns:start', ns).text
                # Parse time (format: 2026-01-04T23:00Z)
                period_start = pd.to_datetime(start_time_str).tz_convert(TIMEZONE)
                
                # Get resolution (commonly PT60M = 60 minutes)
                resolution = period.find('ns:resolution', ns).text
                if resolution == 'PT60M':
                    freq = pd.Timedelta(hours=1)
                elif resolution == 'PT15M':
                    freq = pd.Timedelta(minutes=15)
                else:
                    freq = pd.Timedelta(hours=1)
                
                # Extract all data points
                for point in period.findall('ns:Point', ns):
                    position = int(point.find('ns:position', ns).text)
                    price = float(point.find('ns:price.amount', ns).text)
                    
                    # Compute timestamp
                    timestamp = period_start + (position - 1) * freq
                    
                    timestamps.append(timestamp)
                    prices.append(price)
        
        # Create DataFrame and deduplicate
        df = pd.DataFrame({'timestamp': timestamps, 'price': prices})
        df = df.drop_duplicates(subset=['timestamp'], keep='first').sort_values('timestamp')
        
        logger.info(f"  âœ… åŸå§‹ API è¿”å› {len(timestamps)} ä¸ªæ•°æ®ç‚¹ï¼Œå»é‡å {len(df)} ä¸ª")
        return df
    
    @retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(3))
    def fetch_day_ahead_prices(self, start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:
        """
        acquire day-ahead electricity prices
        """
        logger.info(f"è·å–æ—¥å‰ä»·æ ¼: {start} åˆ° {end}")
        
        # ğŸ”§ Prefer direct REST API call (workaround for entsoe-py bug)
        try:
            df = self._fetch_prices_raw_api(start, end)
            logger.info(f"âœ… æˆåŠŸè·å– {len(df)} æ¡ä»·æ ¼æ•°æ®ï¼ˆä½¿ç”¨åŸå§‹ APIï¼‰")
            return df
        except Exception as raw_api_error:
            logger.warning(f"âš ï¸  åŸå§‹ API è°ƒç”¨å¤±è´¥: {raw_api_error}")
            logger.info(f"  å°è¯•ä½¿ç”¨ entsoe-py åº“...")
        
        # Fallback: use the entsoe-py library
        try:
            prices = self.client.query_day_ahead_prices(
                self.bidding_zone, 
                start=start, 
                end=end
            )
            
            # ğŸ” Detailed debug information
            logger.info(f"  ğŸ“Š åŸå§‹æ•°æ®ç±»å‹: {type(prices)}")
            
            if isinstance(prices, pd.Series):
                logger.info(f"  ğŸ“Š Series é•¿åº¦: {len(prices)}")
                logger.info(f"  ğŸ“Š Index é•¿åº¦: {len(prices.index)}")
                logger.info(f"  ğŸ“Š Values é•¿åº¦: {len(prices.values)}")
                logger.info(f"  ğŸ“Š Index ç±»å‹: {type(prices.index)}")
                logger.info(f"  ğŸ“Š å‰3ä¸ªæ—¶é—´æˆ³: {list(prices.index[:3])}")
                logger.info(f"  ğŸ“Š å3ä¸ªæ—¶é—´æˆ³: {list(prices.index[-3:])}")
                
                # Check for duplicate timestamps
                duplicates = prices.index.duplicated()
                if duplicates.any():
                    logger.warning(f"  âš ï¸  å‘ç° {duplicates.sum()} ä¸ªé‡å¤æ—¶é—´æˆ³ï¼")
                    # Deduplicate: keep the first occurrence
                    prices = prices[~duplicates]
                    logger.info(f"  âœ… å»é‡åé•¿åº¦: {len(prices)}")
            
            elif isinstance(prices, pd.DataFrame):
                logger.info(f"  ğŸ“Š DataFrame å½¢çŠ¶: {prices.shape}")
                logger.info(f"  ğŸ“Š åˆ—å: {list(prices.columns)}")
                logger.info(f"  ğŸ“Š Index é•¿åº¦: {len(prices.index)}")
            
        except Exception as query_error:
            logger.error(f"âŒ API æŸ¥è¯¢å¤±è´¥: {query_error}")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(query_error).__name__}")
            import traceback
            logger.error(f"   è¯¦ç»†å †æ ˆ:\n{traceback.format_exc()}")
            raise
        
        # Try converting to a DataFrame (multiple approaches)
        try:
            if isinstance(prices, pd.Series):
                # Method 1: to_frame()
                df = prices.to_frame(name='price').reset_index()
                df.columns = ['timestamp', 'price']
            else:
                # DataFrame
                df = prices.reset_index()
                if len(df.columns) == 2:
                    df.columns = ['timestamp', 'price']
                else:
                    df = df.iloc[:, [0, 1]]
                    df.columns = ['timestamp', 'price']
            
            logger.info(f"âœ… æˆåŠŸè·å– {len(df)} æ¡ä»·æ ¼æ•°æ®")
            return df
            
        except Exception as convert_error:
            logger.error(f"âŒ DataFrame è½¬æ¢å¤±è´¥: {convert_error}")
            logger.error(f"   å°è¯•å¤‡ç”¨æ–¹æ³•...")
            
            # ğŸ”§ Backup method: manually construct, but ensure lengths align first
            try:
                if isinstance(prices, pd.Series):
                    timestamps = list(prices.index)
                    values = list(prices.values)
                    
                    logger.info(f"  å¤‡ç”¨æ–¹æ³•: timestamps={len(timestamps)}, values={len(values)}")
                    
                    # Force-align lengths
                    min_len = min(len(timestamps), len(values))
                    df = pd.DataFrame({
                        'timestamp': timestamps[:min_len],
                        'price': values[:min_len]
                    })
                    
                    logger.warning(f"  âš ï¸  ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æˆåŠŸï¼Œæ•°æ®é•¿åº¦: {len(df)}")
                    return df
                else:
                    raise ValueError("å¤‡ç”¨æ–¹æ³•ä»…æ”¯æŒ Series ç±»å‹")
                    
            except Exception as backup_error:
                logger.error(f"âŒ å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {backup_error}")
                raise
    
    def _fetch_load_raw_api(self, start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:
        """
        ç›´æ¥è°ƒç”¨ ENTSO-E REST API è·å–è´Ÿè½½é¢„æµ‹
        """
        import requests
        from xml.etree import ElementTree as ET
        
        url = "https://web-api.tp.entsoe.eu/api"
        params = {
            'securityToken': self.api_key,
            'documentType': 'A65',  # System total load forecast
            'processType': 'A01',   # Day ahead
            'outBiddingZone_Domain': self.bidding_zone,
            'periodStart': start.strftime('%Y%m%d%H%M'),
            'periodEnd': end.strftime('%Y%m%d%H%M')
        }
        
        logger.info(f"  ç›´æ¥è°ƒç”¨ ENTSO-E REST API (è´Ÿè½½é¢„æµ‹)...")
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
        
        # ğŸ” Debug: log/save raw XML
        logger.debug(f"  Response status: {response.status_code}")
        logger.debug(f"  Response length: {len(response.content)} bytes")
        
        # Parse XML
        root = ET.fromstring(response.content)
        
        # ğŸ” Try multiple possible XML namespaces
        possible_namespaces = [
            {'ns': 'urn:iec62325.351:tc57wg16:451-6:generationloaddocument:3:0'},  # Generation/Load Documentï¼ˆæ­£ç¡®çš„ï¼ï¼‰
            {'ns': 'urn:iec62325.351:tc57wg16:451-6:loaddocument:3:0'},
            {'ns': 'urn:iec62325.351:tc57wg16:451-3:publicationdocument:7:3'},
            {},  # æ— å‘½åç©ºé—´
        ]
        
        timestamps = []
        loads = []
        timeseries_list = []
        used_ns = {}
        
        for ns in possible_namespaces:
            timeseries_list = root.findall('.//ns:TimeSeries', ns) if ns else root.findall('.//TimeSeries')
            if timeseries_list:
                used_ns = ns
                logger.info(f"  âœ… æ‰¾åˆ° {len(timeseries_list)} ä¸ª TimeSeriesï¼ˆå‘½åç©ºé—´: {ns.get('ns', 'none')}ï¼‰")
                break
        
        if not timeseries_list:
            logger.warning(f"  âš ï¸  æœªæ‰¾åˆ° TimeSeriesï¼Œå°è¯•æŸ¥çœ‹ XML æ ¹èŠ‚ç‚¹...")
            logger.warning(f"  æ ¹èŠ‚ç‚¹: {root.tag}")
            logger.warning(f"  å­èŠ‚ç‚¹: {[child.tag for child in root][:5]}")
            # Try without namespace
            timeseries_list = root.findall('.//TimeSeries')
        
        for timeseries in timeseries_list:
            # Try both namespaced and non-namespaced paths
            periods = timeseries.findall('.//ns:Period', used_ns) if used_ns else timeseries.findall('.//Period')
            
            for period in periods:
                # Get start time
                start_elem = period.find('ns:timeInterval/ns:start', used_ns) if used_ns else period.find('.//start')
                if start_elem is None:
                    continue
                start_time_str = start_elem.text
                period_start = pd.to_datetime(start_time_str).tz_convert(TIMEZONE)
                
                # Get resolution
                res_elem = period.find('ns:resolution', used_ns) if used_ns else period.find('.//resolution')
                resolution = res_elem.text if res_elem is not None else 'PT60M'
                freq = pd.Timedelta(hours=1) if resolution == 'PT60M' else pd.Timedelta(minutes=15)
                
                # Get data points
                points = period.findall('ns:Point', used_ns) if used_ns else period.findall('.//Point')
                for point in points:
                    pos_elem = point.find('ns:position', used_ns) if used_ns else point.find('.//position')
                    qty_elem = point.find('ns:quantity', used_ns) if used_ns else point.find('.//quantity')
                    
                    if pos_elem is None or qty_elem is None:
                        continue
                    
                    position = int(pos_elem.text)
                    load = float(qty_elem.text)
                    
                    timestamp = period_start + (position - 1) * freq
                    timestamps.append(timestamp)
                    loads.append(load)
        
        # Create DataFrame
        if not timestamps:
            logger.warning("  âš ï¸  åŸå§‹ API æœªè¿”å›ä»»ä½•æ•°æ®ï¼Œå°†å°è¯• entsoe-py åº“")
            raise ValueError("No load forecast data from raw API")
        
        df = pd.DataFrame({'timestamp': timestamps, 'load_forecast': loads})
        df = df.drop_duplicates(subset=['timestamp'], keep='first').sort_values('timestamp')
        
        logger.info(f"  âœ… åŸå§‹ API è¿”å› {len(timestamps)} ä¸ªæ•°æ®ç‚¹ï¼Œå»é‡å {len(df)} ä¸ª")
        return df
    
    @retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(3))
    def fetch_load_forecast(self, start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:
        """
        è·å–æ€»è´Ÿè½½é¢„æµ‹ï¼ˆå¢å¼ºç‰ˆï¼šä¼˜å…ˆä½¿ç”¨åŸå§‹ APIï¼‰
        """
        logger.info(f"è·å–è´Ÿè½½é¢„æµ‹: {start} åˆ° {end}")
        
        # Prefer direct REST API call
        try:
            df = self._fetch_load_raw_api(start, end)
            logger.info(f"âœ… æˆåŠŸè·å– {len(df)} æ¡è´Ÿè½½é¢„æµ‹æ•°æ®ï¼ˆä½¿ç”¨åŸå§‹ APIï¼‰")
            return df
        except Exception as raw_api_error:
            logger.warning(f"âš ï¸  åŸå§‹ API è°ƒç”¨å¤±è´¥: {raw_api_error}")
            logger.info(f"  å°è¯•ä½¿ç”¨ entsoe-py åº“...")
        
        # Fallback: use the entsoe-py library
        try:
            load = self.client.query_load_forecast(
                self.bidding_zone,
                start=start,
                end=end
            )
            
            logger.info(f"  ğŸ“Š è´Ÿè½½æ•°æ®ç±»å‹: {type(load)}")
            
            # Handle both DataFrame and Series cases
            if isinstance(load, pd.DataFrame):
                logger.info(f"  ğŸ“Š DataFrame å½¢çŠ¶: {load.shape}")
                logger.info(f"  ğŸ“Š åˆ—å: {list(load.columns)}")
                
                # Check for duplicate index entries
                if load.index.duplicated().any():
                    logger.warning(f"  âš ï¸  å‘ç°é‡å¤ç´¢å¼•ï¼Œæ­£åœ¨å»é‡...")
                    load = load[~load.index.duplicated()]
                
                if load.shape[1] == 1:
                    load_values = load.iloc[:, 0]
                else:
                    load_values = load.mean(axis=1)
                    logger.info(f"  ä½¿ç”¨ {load.shape[1]} åˆ—çš„å¹³å‡å€¼")
                
                df = load_values.to_frame(name='load_forecast').reset_index()
                df.columns = ['timestamp', 'load_forecast']
            else:
                logger.info(f"  ğŸ“Š Series é•¿åº¦: {len(load)}")
                
                # Check for duplicate index entries
                if load.index.duplicated().any():
                    logger.warning(f"  âš ï¸  å‘ç°é‡å¤ç´¢å¼•ï¼Œæ­£åœ¨å»é‡...")
                    load = load[~load.index.duplicated()]
                
                df = load.to_frame(name='load_forecast').reset_index()
                df.columns = ['timestamp', 'load_forecast']
            
            logger.info(f"âœ… æˆåŠŸè·å– {len(df)} æ¡è´Ÿè½½é¢„æµ‹æ•°æ®")
            return df
            
        except Exception as e:
            logger.error(f"âŒ è·å–è´Ÿè½½é¢„æµ‹å¤±è´¥: {e}")
            import traceback
            logger.error(f"   è¯¦ç»†å †æ ˆ:\n{traceback.format_exc()}")
            
            # ğŸ›¡ï¸ Final fallback: return an empty DataFrame so the pipeline can continue
            logger.warning("âš ï¸  æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œè¿”å›ç©ºè´Ÿè½½é¢„æµ‹æ•°æ®")
            logger.warning("âš ï¸  åç»­çš„æ•°æ®æ¸…æ´—æ­¥éª¤ä¼šä½¿ç”¨å‰å‘å¡«å……æˆ–é»˜è®¤å€¼")
            return pd.DataFrame(columns=['timestamp', 'load_forecast'])
    
    def _fetch_wind_solar_raw_api(self, start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:
        """
        ç›´æ¥è°ƒç”¨ ENTSO-E REST API è·å–é£ç”µå’Œå…‰ä¼é¢„æµ‹
        """
        import requests
        from xml.etree import ElementTree as ET
        
        url = "https://web-api.tp.entsoe.eu/api"
        params = {
            'securityToken': self.api_key,
            'documentType': 'A69',  # Wind and solar forecast
            'processType': 'A01',   # Day ahead
            'in_Domain': self.bidding_zone,
            'periodStart': start.strftime('%Y%m%d%H%M'),
            'periodEnd': end.strftime('%Y%m%d%H%M')
        }
        
        logger.info(f"  ç›´æ¥è°ƒç”¨ ENTSO-E REST API (é£å…‰é¢„æµ‹)...")
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
        
        # Parse XML
        root = ET.fromstring(response.content)
        ns = {'ns': 'urn:iec62325.351:tc57wg16:451-6:generationloaddocument:3:0'}
        
        wind_data = {}
        solar_data = {}
        
        for timeseries in root.findall('.//ns:TimeSeries', ns):
            # Get generation type
            psr_type_elem = timeseries.find('.//ns:MktPSRType/ns:psrType', ns)
            if psr_type_elem is None:
                continue
            psr_type = psr_type_elem.text
            
            for period in timeseries.findall('.//ns:Period', ns):
                start_time_str = period.find('ns:timeInterval/ns:start', ns).text
                period_start = pd.to_datetime(start_time_str).tz_convert(TIMEZONE)
                
                resolution = period.find('ns:resolution', ns).text
                freq = pd.Timedelta(hours=1) if resolution == 'PT60M' else pd.Timedelta(minutes=15)
                
                for point in period.findall('ns:Point', ns):
                    position = int(point.find('ns:position', ns).text)
                    quantity = float(point.find('ns:quantity', ns).text)
                    
                    timestamp = period_start + (position - 1) * freq
                    
                    # B19 = Solar, B18 = Wind Offshore, B19 = Wind Onshore
                    if psr_type == 'B16':  # Solar
                        solar_data[timestamp] = solar_data.get(timestamp, 0) + quantity
                    elif psr_type in ['B18', 'B19']:  # Wind (Offshore + Onshore)
                        wind_data[timestamp] = wind_data.get(timestamp, 0) + quantity
        
        # Create DataFrame
        all_timestamps = sorted(set(list(wind_data.keys()) + list(solar_data.keys())))
        
        df = pd.DataFrame({
            'timestamp': all_timestamps,
            'wind_forecast': [wind_data.get(ts, 0) for ts in all_timestamps],
            'solar_forecast': [solar_data.get(ts, 0) for ts in all_timestamps]
        })
        
        logger.info(f"  âœ… é£å…‰é¢„æµ‹è·å–æˆåŠŸ: {len(df)} ä¸ªæ—¶é—´ç‚¹")
        return df
    
    @retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(3))
    def fetch_wind_solar_forecast(self, start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:
        """
        è·å–é£ç”µå’Œå…‰ä¼å‘ç”µé¢„æµ‹ï¼ˆä¼˜å…ˆä½¿ç”¨åŸå§‹ APIï¼‰
        """
        logger.info(f"è·å–é£å…‰é¢„æµ‹: {start} åˆ° {end}")
        
        # Prefer direct REST API call
        try:
            df = self._fetch_wind_solar_raw_api(start, end)
            logger.info(f"âœ… æˆåŠŸè·å– {len(df)} æ¡é£å…‰é¢„æµ‹æ•°æ®ï¼ˆä½¿ç”¨åŸå§‹ APIï¼‰")
            return df
        except Exception as raw_api_error:
            logger.warning(f"âš ï¸  åŸå§‹ API è°ƒç”¨å¤±è´¥: {raw_api_error}")
            logger.info(f"  å°è¯•ä½¿ç”¨ entsoe-py åº“...")
        
        # Fallback: use the entsoe-py library
        try:
            # Fetch wind and solar forecasts
            data = self.client.query_wind_and_solar_forecast(
                self.bidding_zone,
                start=start,
                end=end,
                psr_type=None  # è·å–æ‰€æœ‰ç±»å‹
            )
            
            # Initialize result DataFrame
            result_df = pd.DataFrame(index=data.index)
            
            # Extract wind data (may contain multiple types)
            wind_total = 0
            wind_columns = []
            
            for col in data.columns:
                if 'wind' in col.lower():
                    wind_columns.append(col)
                    if isinstance(data[col], pd.Series):
                        wind_total = wind_total + data[col] if isinstance(wind_total, pd.Series) else data[col]
                    
            if isinstance(wind_total, pd.Series) and len(wind_total) > 0:
                result_df['wind_forecast'] = wind_total
                logger.info(f"é£ç”µæ•°æ®æ¥æº: {wind_columns}")
            else:
                result_df['wind_forecast'] = 0
                logger.warning("æœªæ‰¾åˆ°é£ç”µæ•°æ®ï¼Œå¡«å……ä¸º0")
            
            # Extract solar (PV) data
            if 'Solar' in data.columns:
                result_df['solar_forecast'] = data['Solar']
                logger.info("å…‰ä¼æ•°æ®æ¥æº: ['Solar']")
            elif 'solar' in [c.lower() for c in data.columns]:
                # Look for a lowercase 'solar' column
                solar_col = [c for c in data.columns if 'solar' in c.lower()][0]
                result_df['solar_forecast'] = data[solar_col]
                logger.info(f"å…‰ä¼æ•°æ®æ¥æº: ['{solar_col}']")
            else:
                result_df['solar_forecast'] = 0
                logger.warning("æœªæ‰¾åˆ°å…‰ä¼æ•°æ®ï¼Œå¡«å……ä¸º0")
            
            # Reset index and select required columns
            result_df = result_df.reset_index()
            # Ensure first column is the timestamp
            if result_df.columns[0] != 'timestamp':
                result_df = result_df.rename(columns={result_df.columns[0]: 'timestamp'})
            result_df = result_df[['timestamp', 'wind_forecast', 'solar_forecast']]
            
            logger.info(f"æˆåŠŸè·å– {len(result_df)} æ¡é£å…‰é¢„æµ‹æ•°æ®")
            logger.info(f"  é£ç”µèŒƒå›´: {result_df['wind_forecast'].min():.1f} - {result_df['wind_forecast'].max():.1f} MW")
            logger.info(f"  å…‰ä¼èŒƒå›´: {result_df['solar_forecast'].min():.1f} - {result_df['solar_forecast'].max():.1f} MW")
            return result_df
            
        except Exception as e:
            logger.error(f"è·å–é£å…‰é¢„æµ‹å¤±è´¥: {e}")
            # Return empty DataFrame to avoid breaking the pipeline
            logger.warning("è¿”å›ç©ºé£å…‰é¢„æµ‹æ•°æ®")
            return pd.DataFrame(columns=['timestamp', 'wind_forecast', 'solar_forecast'])
    
    def fetch_all_market_data(self, start_date: str, end_date: str) -> pd.DataFrame:
        """
        è·å–æ‰€æœ‰å¸‚åœºæ•°æ®å¹¶åˆå¹¶
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸå­—ç¬¦ä¸² 'YYYY-MM-DD'
            end_date: ç»“æŸæ—¥æœŸå­—ç¬¦ä¸² 'YYYY-MM-DD'
            
        Returns:
            åˆå¹¶åçš„å®Œæ•´DataFrame
        """
        # Convert to timezone-aware timestamps
        start = pd.Timestamp(start_date, tz=TIMEZONE)
        end = pd.Timestamp(end_date, tz=TIMEZONE)
        
        # Fetch each type of data
        prices_df = self.fetch_day_ahead_prices(start, end)
        load_df = self.fetch_load_forecast(start, end)
        wind_solar_df = self.fetch_wind_solar_forecast(start, end)
        
        # Log data shapes
        logger.info(f"æ•°æ®å½¢çŠ¶: ä»·æ ¼={len(prices_df)}, è´Ÿè½½={len(load_df)}, é£å…‰={len(wind_solar_df)}")
        
        # Merge data
        df = prices_df.merge(load_df, on='timestamp', how='left')
        logger.info(f"ä»·æ ¼+è´Ÿè½½åˆå¹¶å: {len(df)} æ¡è®°å½•")
        
        df = df.merge(wind_solar_df, on='timestamp', how='left')
        logger.info(f"æœ€ç»ˆåˆå¹¶å: {len(df)} æ¡è®°å½•")
        
        # Fill missing values (using modern pandas syntax)
        df = df.ffill().bfill()
        
        logger.info(f"âœ… åˆå¹¶å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
        return df


def main():
    """Test function"""
    client = ENTSOEClient()
    
    # Test fetching the most recent 3 days of data
    end = pd.Timestamp.now(tz=TIMEZONE)
    start = end - pd.Timedelta(days=3)
    
    df = client.fetch_all_market_data(
        start.strftime('%Y-%m-%d'),
        end.strftime('%Y-%m-%d')
    )
    
    print(df.head())
    print(f"\næ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"\nåˆ—å: {df.columns.tolist()}")


if __name__ == "__main__":
    main()