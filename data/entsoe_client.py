"""
ENTSO-Eæ•°æ®è·å–å®¢æˆ·ç«¯
"""
from entsoe import EntsoePandasClient
import pandas as pd
from datetime import datetime, timedelta
from config.settings import ENTSOE_API_KEY, BIDDING_ZONE, TIMEZONE
import time
from tenacity import retry, wait_exponential, stop_after_attempt
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ENTSOEClient:
    """ENTSO-E Transparency Platformæ•°æ®å®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–ENTSO-Eå®¢æˆ·ç«¯
        
        Args:
            api_key: ENTSO-E APIå¯†é’¥,å¦‚æœæœªæä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        self.api_key = api_key or ENTSOE_API_KEY
        if not self.api_key:
            raise ValueError("ENTSO-E API keyæœªè®¾ç½®,è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®ENTSOE_API_KEY")
        
        self.client = EntsoePandasClient(api_key=self.api_key)
        self.bidding_zone = BIDDING_ZONE
        
    @retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(3))
    def fetch_day_ahead_prices(self, start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:
        """
        è·å–æ—¥å‰å¸‚åœºä»·æ ¼ï¼ˆå¢å¼ºç‰ˆï¼šå¸¦è¯¦ç»†è°ƒè¯•ä¿¡æ¯å’Œå®¹é”™å¤„ç†ï¼‰
        """
        logger.info(f"è·å–æ—¥å‰ä»·æ ¼: {start} åˆ° {end}")
        
        try:
            prices = self.client.query_day_ahead_prices(
                self.bidding_zone, 
                start=start, 
                end=end
            )
            
            # ğŸ” è¯¦ç»†è°ƒè¯•ä¿¡æ¯
            logger.info(f"  ğŸ“Š åŸå§‹æ•°æ®ç±»å‹: {type(prices)}")
            
            if isinstance(prices, pd.Series):
                logger.info(f"  ğŸ“Š Series é•¿åº¦: {len(prices)}")
                logger.info(f"  ğŸ“Š Index é•¿åº¦: {len(prices.index)}")
                logger.info(f"  ğŸ“Š Values é•¿åº¦: {len(prices.values)}")
                logger.info(f"  ğŸ“Š Index ç±»å‹: {type(prices.index)}")
                logger.info(f"  ğŸ“Š å‰3ä¸ªæ—¶é—´æˆ³: {list(prices.index[:3])}")
                logger.info(f"  ğŸ“Š å3ä¸ªæ—¶é—´æˆ³: {list(prices.index[-3:])}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„æ—¶é—´æˆ³
                duplicates = prices.index.duplicated()
                if duplicates.any():
                    logger.warning(f"  âš ï¸  å‘ç° {duplicates.sum()} ä¸ªé‡å¤æ—¶é—´æˆ³ï¼")
                    # å»é‡ï¼šä¿ç•™ç¬¬ä¸€ä¸ª
                    prices = prices[~duplicates]
                    logger.info(f"  âœ… å»é‡åé•¿åº¦: {len(prices)}")
            
            elif isinstance(prices, pd.DataFrame):
                logger.info(f"  ğŸ“Š DataFrame å½¢çŠ¶: {prices.shape}")
                logger.info(f"  ğŸ“Š åˆ—å: {list(prices.columns)}")
                logger.info(f"  ğŸ“Š Index é•¿åº¦: {len(prices.index)}")
            
        except Exception as query_error:
            logger.error(f"âŒ API æŸ¥è¯¢å¤±è´¥: {query_error}")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(query_error).__name__}")
            import traceback
            logger.error(f"   è¯¦ç»†å †æ ˆ:\n{traceback.format_exc()}")
            raise
        
        # å°è¯•è½¬æ¢ä¸º DataFrameï¼ˆå¤šç§æ–¹æ³•ï¼‰
        try:
            if isinstance(prices, pd.Series):
                # æ–¹æ³•1: to_frame()
                df = prices.to_frame(name='price').reset_index()
                df.columns = ['timestamp', 'price']
            else:
                # DataFrame
                df = prices.reset_index()
                if len(df.columns) == 2:
                    df.columns = ['timestamp', 'price']
                else:
                    df = df.iloc[:, [0, 1]]
                    df.columns = ['timestamp', 'price']
            
            logger.info(f"âœ… æˆåŠŸè·å– {len(df)} æ¡ä»·æ ¼æ•°æ®")
            return df
            
        except Exception as convert_error:
            logger.error(f"âŒ DataFrame è½¬æ¢å¤±è´¥: {convert_error}")
            logger.error(f"   å°è¯•å¤‡ç”¨æ–¹æ³•...")
            
            # ğŸ”§ å¤‡ç”¨æ–¹æ³•ï¼šæ‰‹åŠ¨æ„é€ ï¼Œä½†å…ˆç¡®ä¿é•¿åº¦ä¸€è‡´
            try:
                if isinstance(prices, pd.Series):
                    timestamps = list(prices.index)
                    values = list(prices.values)
                    
                    logger.info(f"  å¤‡ç”¨æ–¹æ³•: timestamps={len(timestamps)}, values={len(values)}")
                    
                    # å¼ºåˆ¶å¯¹é½é•¿åº¦
                    min_len = min(len(timestamps), len(values))
                    df = pd.DataFrame({
                        'timestamp': timestamps[:min_len],
                        'price': values[:min_len]
                    })
                    
                    logger.warning(f"  âš ï¸  ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æˆåŠŸï¼Œæ•°æ®é•¿åº¦: {len(df)}")
                    return df
                else:
                    raise ValueError("å¤‡ç”¨æ–¹æ³•ä»…æ”¯æŒ Series ç±»å‹")
                    
            except Exception as backup_error:
                logger.error(f"âŒ å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {backup_error}")
                raise
    
    @retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(3))
    def fetch_load_forecast(self, start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:
        """
        è·å–æ€»è´Ÿè½½é¢„æµ‹ï¼ˆå¢å¼ºç‰ˆï¼šå¸¦è°ƒè¯•ä¿¡æ¯ï¼‰
        """
        logger.info(f"è·å–è´Ÿè½½é¢„æµ‹: {start} åˆ° {end}")
        
        try:
            load = self.client.query_load_forecast(
                self.bidding_zone,
                start=start,
                end=end
            )
            
            logger.info(f"  ğŸ“Š è´Ÿè½½æ•°æ®ç±»å‹: {type(load)}")
            
            # å¤„ç†DataFrameå’ŒSeriesä¸¤ç§æƒ…å†µ
            if isinstance(load, pd.DataFrame):
                logger.info(f"  ğŸ“Š DataFrame å½¢çŠ¶: {load.shape}")
                logger.info(f"  ğŸ“Š åˆ—å: {list(load.columns)}")
                
                # æ£€æŸ¥é‡å¤ç´¢å¼•
                if load.index.duplicated().any():
                    logger.warning(f"  âš ï¸  å‘ç°é‡å¤ç´¢å¼•ï¼Œæ­£åœ¨å»é‡...")
                    load = load[~load.index.duplicated()]
                
                if load.shape[1] == 1:
                    load_values = load.iloc[:, 0]
                else:
                    load_values = load.mean(axis=1)
                    logger.info(f"  ä½¿ç”¨ {load.shape[1]} åˆ—çš„å¹³å‡å€¼")
                
                df = load_values.to_frame(name='load_forecast').reset_index()
                df.columns = ['timestamp', 'load_forecast']
            else:
                logger.info(f"  ğŸ“Š Series é•¿åº¦: {len(load)}")
                
                # æ£€æŸ¥é‡å¤ç´¢å¼•
                if load.index.duplicated().any():
                    logger.warning(f"  âš ï¸  å‘ç°é‡å¤ç´¢å¼•ï¼Œæ­£åœ¨å»é‡...")
                    load = load[~load.index.duplicated()]
                
                df = load.to_frame(name='load_forecast').reset_index()
                df.columns = ['timestamp', 'load_forecast']
            
            logger.info(f"âœ… æˆåŠŸè·å– {len(df)} æ¡è´Ÿè½½é¢„æµ‹æ•°æ®")
            return df
            
        except Exception as e:
            logger.error(f"âŒ è·å–è´Ÿè½½é¢„æµ‹å¤±è´¥: {e}")
            import traceback
            logger.error(f"   è¯¦ç»†å †æ ˆ:\n{traceback.format_exc()}")
            raise
    
    @retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(3))
    def fetch_wind_solar_forecast(self, start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:
        """
        è·å–é£ç”µå’Œå…‰ä¼å‘ç”µé¢„æµ‹
        
        Args:
            start: å¼€å§‹æ—¶é—´
            end: ç»“æŸæ—¶é—´
            
        Returns:
            DataFrame with columns: timestamp, wind_forecast, solar_forecast
        """
        try:
            logger.info(f"è·å–é£å…‰é¢„æµ‹: {start} åˆ° {end}")
            
            # è·å–é£ç”µå’Œå…‰ä¼é¢„æµ‹
            data = self.client.query_wind_and_solar_forecast(
                self.bidding_zone,
                start=start,
                end=end,
                psr_type=None  # è·å–æ‰€æœ‰ç±»å‹
            )
            
            # åˆå§‹åŒ–ç»“æœDataFrame
            result_df = pd.DataFrame(index=data.index)
            
            # æå–é£ç”µæ•°æ®ï¼ˆå¯èƒ½æœ‰å¤šç§ç±»å‹ï¼‰
            wind_total = 0
            wind_columns = []
            
            for col in data.columns:
                if 'wind' in col.lower():
                    wind_columns.append(col)
                    if isinstance(data[col], pd.Series):
                        wind_total = wind_total + data[col] if isinstance(wind_total, pd.Series) else data[col]
                    
            if isinstance(wind_total, pd.Series) and len(wind_total) > 0:
                result_df['wind_forecast'] = wind_total
                logger.info(f"é£ç”µæ•°æ®æ¥æº: {wind_columns}")
            else:
                result_df['wind_forecast'] = 0
                logger.warning("æœªæ‰¾åˆ°é£ç”µæ•°æ®ï¼Œå¡«å……ä¸º0")
            
            # æå–å…‰ä¼æ•°æ®
            if 'Solar' in data.columns:
                result_df['solar_forecast'] = data['Solar']
                logger.info("å…‰ä¼æ•°æ®æ¥æº: ['Solar']")
            elif 'solar' in [c.lower() for c in data.columns]:
                # æŸ¥æ‰¾å°å†™solaråˆ—
                solar_col = [c for c in data.columns if 'solar' in c.lower()][0]
                result_df['solar_forecast'] = data[solar_col]
                logger.info(f"å…‰ä¼æ•°æ®æ¥æº: ['{solar_col}']")
            else:
                result_df['solar_forecast'] = 0
                logger.warning("æœªæ‰¾åˆ°å…‰ä¼æ•°æ®ï¼Œå¡«å……ä¸º0")
            
            # é‡ç½®ç´¢å¼•å¹¶é€‰æ‹©éœ€è¦çš„åˆ—
            result_df = result_df.reset_index()
            # ç¡®ä¿ç¬¬ä¸€åˆ—æ˜¯æ—¶é—´æˆ³
            if result_df.columns[0] != 'timestamp':
                result_df = result_df.rename(columns={result_df.columns[0]: 'timestamp'})
            result_df = result_df[['timestamp', 'wind_forecast', 'solar_forecast']]
            
            logger.info(f"æˆåŠŸè·å– {len(result_df)} æ¡é£å…‰é¢„æµ‹æ•°æ®")
            logger.info(f"  é£ç”µèŒƒå›´: {result_df['wind_forecast'].min():.1f} - {result_df['wind_forecast'].max():.1f} MW")
            logger.info(f"  å…‰ä¼èŒƒå›´: {result_df['solar_forecast'].min():.1f} - {result_df['solar_forecast'].max():.1f} MW")
            return result_df
            
        except Exception as e:
            logger.error(f"è·å–é£å…‰é¢„æµ‹å¤±è´¥: {e}")
            # è¿”å›ç©ºDataFrameé¿å…ç®¡é“ä¸­æ–­
            logger.warning("è¿”å›ç©ºé£å…‰é¢„æµ‹æ•°æ®")
            return pd.DataFrame(columns=['timestamp', 'wind_forecast', 'solar_forecast'])
    
    def fetch_all_market_data(self, start_date: str, end_date: str) -> pd.DataFrame:
        """
        è·å–æ‰€æœ‰å¸‚åœºæ•°æ®å¹¶åˆå¹¶
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸå­—ç¬¦ä¸² 'YYYY-MM-DD'
            end_date: ç»“æŸæ—¥æœŸå­—ç¬¦ä¸² 'YYYY-MM-DD'
            
        Returns:
            åˆå¹¶åçš„å®Œæ•´DataFrame
        """
        # è½¬æ¢ä¸ºtimezone-aware timestamps
        start = pd.Timestamp(start_date, tz=TIMEZONE)
        end = pd.Timestamp(end_date, tz=TIMEZONE)
        
        # è·å–å„ç±»æ•°æ®
        prices_df = self.fetch_day_ahead_prices(start, end)
        load_df = self.fetch_load_forecast(start, end)
        wind_solar_df = self.fetch_wind_solar_forecast(start, end)
        
        # åˆå¹¶æ•°æ®
        df = prices_df.merge(load_df, on='timestamp', how='left')
        df = df.merge(wind_solar_df, on='timestamp', how='left')
        
        # å¡«å……ç¼ºå¤±å€¼ï¼ˆä½¿ç”¨æ–°ç‰ˆpandasè¯­æ³•ï¼‰
        df = df.ffill().bfill()
        
        logger.info(f"åˆå¹¶åå…± {len(df)} æ¡è®°å½•")
        return df


def main():
    """æµ‹è¯•å‡½æ•°"""
    client = ENTSOEClient()
    
    # æµ‹è¯•è·å–æœ€è¿‘3å¤©çš„æ•°æ®
    end = pd.Timestamp.now(tz=TIMEZONE)
    start = end - pd.Timedelta(days=3)
    
    df = client.fetch_all_market_data(
        start.strftime('%Y-%m-%d'),
        end.strftime('%Y-%m-%d')
    )
    
    print(df.head())
    print(f"\næ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"\nåˆ—å: {df.columns.tolist()}")


if __name__ == "__main__":
    main()

