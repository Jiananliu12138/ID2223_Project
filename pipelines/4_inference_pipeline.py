"""
æŽ¨ç†ç®¡é“
èŽ·å–æœ€æ–°ç‰¹å¾,ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡åž‹é¢„æµ‹æœªæ¥24å°æ—¶ç”µä»·
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from features.feature_groups import FeatureStoreManager
from features.feature_engineering import FeatureEngineer
from models.trainer import ElectricityPriceModel
from config.settings import MODEL_NAME, TIMEZONE
import logging
import json

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def run_inference():
    """æŽ¨ç†æµç¨‹"""
    logger.info(f"\n{'='*70}")
    logger.info(f"æŽ¨ç†ç®¡é“ - {datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"{'='*70}\n")
    
    try:
        # 1. è¿žæŽ¥Feature Store
        logger.info("æ­¥éª¤ 1/6: è¿žæŽ¥Feature Store...")
        fsm = FeatureStoreManager()
        
        # 2. ä»Ž Feature Groups è¯»å–åŽŸå§‹æ•°æ®
        logger.info("æ­¥éª¤ 2/6: ä»Ž Feature Groups è¯»å–åŽŸå§‹æ•°æ®...")
        
        # èŽ·å–åŒ…å«åŽ†å²æ•°æ®çš„æ—¶é—´èŒƒå›´ï¼ˆéœ€è¦åŽ†å²æ•°æ®æ¥è®¡ç®—æ»žåŽç‰¹å¾ï¼‰
        now = datetime.now(TIMEZONE)
        # èŽ·å–è¿‡åŽ»7å¤©åˆ°æœªæ¥2å¤©çš„æ•°æ®ï¼ˆç¡®ä¿æœ‰è¶³å¤Ÿçš„åŽ†å²æ•°æ®è®¡ç®—æ»žåŽç‰¹å¾ï¼‰
        start_time = now - timedelta(days=7)
        end_time = now + timedelta(days=2)
        
        logger.info(f"  æ—¶é—´èŒƒå›´: {start_time.strftime('%Y-%m-%d')} åˆ° {end_time.strftime('%Y-%m-%d')}")
        
        # ä»ŽåŽŸå§‹ Feature Groups è¯»å–æ•°æ®
        df = fsm.read_raw_feature_groups(
            start_time=start_time.strftime('%Y-%m-%d %H:%M:%S'),
            end_time=end_time.strftime('%Y-%m-%d %H:%M:%S')
        )
        
        logger.info(f"  âœ… è¯»å–äº† {len(df)} æ¡åŽŸå§‹è®°å½•")
        
        # 3. ç‰¹å¾å·¥ç¨‹
        logger.info("æ­¥éª¤ 3/6: ç‰¹å¾å·¥ç¨‹...")
        logger.info(f"  åŽŸå§‹ç‰¹å¾æ•°: {len(df.columns)}")
        
        df = FeatureEngineer.engineer_features_pipeline(df, include_lag=True)
        
        logger.info(f"  å·¥ç¨‹ç‰¹å¾æ•°: {len(df.columns)}")
        
        # å°†æ•°æ®åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼šè¿‡åŽ»7å¤©ç”¨äºŽ backtestï¼Œæœªæ¥2å¤©ç”¨äºŽ forecast
        backtest_start = now - timedelta(days=7)
        backtest_end = now  # ä¸åŒ…å«å½“å‰æ—¶åˆ»
        forecast_start = now
        forecast_end = now + timedelta(days=2)

        logger.info(f"  å°†æ‰§è¡Œ backtest: {backtest_start} åˆ° {backtest_end} ï¼Œä»¥åŠ forecast: {forecast_start} åˆ° {forecast_end}")

        # å­é›†é€‰æ‹©
        backtest_df = df[(df['timestamp'] >= backtest_start) & (df['timestamp'] < backtest_end)].copy()
        forecast_df = df[(df['timestamp'] >= forecast_start) & (df['timestamp'] <= forecast_end)].copy()

        logger.info(f"  å­é›†å¤§å°: backtest={len(backtest_df)}, forecast={len(forecast_df)}")
        
        # 4. åŠ è½½æ¨¡åž‹
        logger.info("æ­¥éª¤ 4/6: åŠ è½½æ¨¡åž‹...")
        
        model_path = f"models/{MODEL_NAME}.pkl"
        
        if not os.path.exists(model_path):
            # å°è¯•ä»ŽHopsworksä¸‹è½½
            logger.info("  æœ¬åœ°æ¨¡åž‹ä¸å­˜åœ¨,ä»ŽHopsworksä¸‹è½½...")
            mr = fsm.get_model_registry()
            model_obj = mr.get_model(MODEL_NAME, version=1)
            model_dir = model_obj.download()
            model_path = os.path.join(model_dir, f"{MODEL_NAME}.pkl")
        
        model = ElectricityPriceModel()
        model.load_model(model_path)
        
        # 5. å¯¹ä¸¤ä¸ªå­é›†åˆ†åˆ«æ‰§è¡Œæ•°æ®æ¸…ç†å’Œé¢„æµ‹ï¼ˆbacktest ä¸Ž forecastï¼‰å¹¶åˆå¹¶ç»“æžœ
        logger.info("æ­¥éª¤ 5/6: åˆ†åˆ«å¯¹ backtest ä¸Ž forecast æ‰§è¡Œæ•°æ®æ¸…ç†å’Œé¢„æµ‹...")

        all_results = []

        tasks = [
            ("backtest", backtest_df),
            ("forecast", forecast_df)
        ]

        feature_cols = model.feature_names

        for mode_label, subset in tasks:
            if subset is None or len(subset) == 0:
                logger.info(f"  è·³è¿‡ {mode_label}: æ²¡æœ‰å¯ç”¨æ•°æ®")
                continue

            # ç¡®ä¿æŒ‰æ—¶é—´æŽ’åº
            subset = subset.sort_values('timestamp').reset_index(drop=True)

            timestamps = subset['timestamp'].copy()

            # ç§»é™¤éžæ•°å€¼åˆ—
            exclude_cols = ['timestamp']
            cols_to_drop = [col for col in subset.columns if col in exclude_cols or subset[col].dtype == 'object']

            if cols_to_drop:
                logger.info(f"  [{mode_label}] ç§»é™¤åˆ—: {cols_to_drop}")
                subset_clean = subset.drop(columns=cols_to_drop)
            else:
                subset_clean = subset.copy()

            # æ£€æŸ¥ç¼ºå¤±çš„ç‰¹å¾å¹¶å¡«å……
            missing_features = set(feature_cols) - set(subset_clean.columns)
            if missing_features:
                logger.warning(f"  [{mode_label}] âš ï¸ ç¼ºå¤±ç‰¹å¾: {missing_features}ï¼Œå°†ç”¨0å¡«å……")
                for feat in missing_features:
                    subset_clean[feat] = 0

            X_pred = subset_clean[feature_cols].fillna(0)
            logger.info(f"  [{mode_label}] âœ… é¢„æµ‹ç‰¹å¾: {len(feature_cols)} ä¸ª, å¾…é¢„æµ‹è¡Œæ•°: {len(X_pred)}")

            preds = model.predict(X_pred)
            logger.info(f"  [{mode_label}] âœ… å®Œæˆ {len(preds)} ä¸ªé¢„æµ‹")

            # æž„å»ºç»“æžœDataFrame
            res_df = pd.DataFrame({
                'timestamp': timestamps,
                'predicted_price': preds,
                'mode': mode_label
            })

            if 'price' in subset.columns:
                res_df['actual_price'] = subset['price'].values
                res_df['error'] = res_df['actual_price'] - res_df['predicted_price']
                res_df['abs_error'] = np.abs(res_df['error'])

            all_results.append(res_df)

        if len(all_results) == 0:
            logger.error("æ²¡æœ‰ä»»ä½•å¯é¢„æµ‹çš„æ•°æ®ï¼ˆbacktest å’Œ forecast éƒ½ä¸ºç©ºï¼‰")
            return False

        results_df = pd.concat(all_results, ignore_index=True).sort_values('timestamp').reset_index(drop=True)
        logger.info(f"  âœ… åˆå¹¶åŽæ€»å…± {len(results_df)} æ¡é¢„æµ‹ç»“æžœ")
        
        # 6. ä¿å­˜é¢„æµ‹ç»“æžœ
        logger.info("æ­¥éª¤ 6/6: ä¿å­˜é¢„æµ‹ç»“æžœ...")
        
        # ä¿å­˜ä¸ºJSON(ä¾›UIä½¿ç”¨)
        output_dir = "predictions"
        os.makedirs(output_dir, exist_ok=True)
        
        output_file = os.path.join(
            output_dir, 
            f"predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        
        # è½¬æ¢ä¸ºJSONæ ¼å¼
        results_json = results_df.to_dict(orient='records')
        
        with open(output_file, 'w') as f:
            json.dump(results_json, f, indent=2, default=str)
        
        # åŒæ—¶ä¿å­˜æœ€æ–°é¢„æµ‹(è¦†ç›–)
        latest_file = os.path.join(output_dir, "latest_predictions.json")
        with open(latest_file, 'w') as f:
            json.dump(results_json, f, indent=2, default=str)
        
        logger.info(f"  âœ… é¢„æµ‹ç»“æžœå·²ä¿å­˜åˆ°: {output_file}")
        logger.info(f"  âœ… æœ€æ–°é¢„æµ‹: {latest_file}")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        logger.info(f"  é¢„æµ‹æ—¶æ®µ: {len(results_df)} å°æ—¶")
        logger.info(f"  æ—¶é—´èŒƒå›´: {results_df['timestamp'].min()} åˆ° {results_df['timestamp'].max()}")
        logger.info(f"  å¹³å‡é¢„æµ‹ä»·æ ¼: {results_df['predicted_price'].mean():.2f} EUR/MWh")
        logger.info(f"  æœ€ä½Žé¢„æµ‹ä»·æ ¼: {results_df['predicted_price'].min():.2f} EUR/MWh")
        logger.info(f"  æœ€é«˜é¢„æµ‹ä»·æ ¼: {results_df['predicted_price'].max():.2f} EUR/MWh")
        
        if 'actual_price' in results_df.columns:
            mae = results_df['abs_error'].mean()
            logger.info(f"  âœ… MAEï¼ˆä¸Žå®žé™…ä»·æ ¼å¯¹æ¯”ï¼‰: {mae:.2f} EUR/MWh")
        
        # æ‰¾åˆ°æœ€ä¾¿å®œçš„4å°æ—¶æ—¶æ®µ(ç”¨äºŽ"æ´—è¡£è®¡æ—¶å™¨")
        logger.info(f"\nðŸ’¡ æœ€ä¾¿å®œçš„4å°æ—¶ï¼ˆæŽ¨èç”¨ç”µæ—¶æ®µï¼‰:")
        cheapest_hours = results_df.nsmallest(4, 'predicted_price')
        for _, row in cheapest_hours.iterrows():
            logger.info(f"  ðŸ• {row['timestamp']}: {row['predicted_price']:.2f} EUR/MWh")
        
        logger.info(f"\n{'='*70}")
        logger.info("âœ… æŽ¨ç†å®Œæˆ!")
        logger.info(f"{'='*70}\n")
        
        return True
        
    except Exception as e:
        logger.error(f"\n{'='*70}")
        logger.error("âŒ æŽ¨ç†å¤±è´¥!")
        logger.error(f"é”™è¯¯ä¿¡æ¯: {e}")
        logger.error(f"{'='*70}\n")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    success = run_inference()
    
    if success:
        logger.info("æŽ¨ç†ç®¡é“æ‰§è¡ŒæˆåŠŸ")
        exit(0)
    else:
        logger.error("æŽ¨ç†ç®¡é“æ‰§è¡Œå¤±è´¥")
        exit(1)


if __name__ == "__main__":
    main()

