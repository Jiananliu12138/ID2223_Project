"""
æ¨ç†ç®¡é“
è·å–æœ€æ–°ç‰¹å¾,ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹æœªæ¥24å°æ—¶ç”µä»·
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from features.feature_groups import FeatureStoreManager
from features.feature_engineering import FeatureEngineer
from models.trainer import ElectricityPriceModel
from config.settings import MODEL_NAME, TIMEZONE
import logging
import json

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def run_inference():
    """æ¨ç†æµç¨‹"""
    logger.info(f"\n{'='*70}")
    logger.info(f"æ¨ç†ç®¡é“ - {datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"{'='*70}\n")
    
    try:
        # 1. è¿æ¥Feature Store
        logger.info("æ­¥éª¤ 1/6: è¿æ¥Feature Store...")
        fsm = FeatureStoreManager()
        
        # 2. ä» Feature Groups è¯»å–åŸå§‹æ•°æ®
        logger.info("æ­¥éª¤ 2/6: ä» Feature Groups è¯»å–åŸå§‹æ•°æ®...")
        
        # è·å–åŒ…å«å†å²æ•°æ®çš„æ—¶é—´èŒƒå›´ï¼ˆéœ€è¦å†å²æ•°æ®æ¥è®¡ç®—æ»åç‰¹å¾ï¼‰
        now = datetime.now(TIMEZONE)
        # è·å–è¿‡å»7å¤©åˆ°æœªæ¥2å¤©çš„æ•°æ®ï¼ˆç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®è®¡ç®—æ»åç‰¹å¾ï¼‰
        start_time = now - timedelta(days=7)
        end_time = now + timedelta(days=2)
        
        logger.info(f"  æ—¶é—´èŒƒå›´: {start_time.strftime('%Y-%m-%d')} åˆ° {end_time.strftime('%Y-%m-%d')}")
        
        # ä»åŸå§‹ Feature Groups è¯»å–æ•°æ®
        df = fsm.read_raw_feature_groups(
            start_time=start_time.strftime('%Y-%m-%d %H:%M:%S'),
            end_time=end_time.strftime('%Y-%m-%d %H:%M:%S')
        )
        
        logger.info(f"  âœ… è¯»å–äº† {len(df)} æ¡åŸå§‹è®°å½•")
        
        # 3. ç‰¹å¾å·¥ç¨‹
        logger.info("æ­¥éª¤ 3/6: ç‰¹å¾å·¥ç¨‹...")
        logger.info(f"  åŸå§‹ç‰¹å¾æ•°: {len(df.columns)}")
        
        df = FeatureEngineer.engineer_features_pipeline(df, include_lag=True)
        
        logger.info(f"  å·¥ç¨‹ç‰¹å¾æ•°: {len(df.columns)}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªæ¥æ•°æ®
        future_data = df[df['timestamp'] >= now].copy()
        
        if len(future_data) > 0:
            # æœ‰æœªæ¥æ•°æ®ï¼Œç”¨äºçœŸå®é¢„æµ‹
            df = future_data
            prediction_mode = "forecast"
            logger.info(f"  âœ… ä½¿ç”¨æœªæ¥æ•°æ®: {len(df)} æ¡ï¼ˆçœŸå®é¢„æµ‹æ¨¡å¼ï¼‰")
        else:
            # æ²¡æœ‰æœªæ¥æ•°æ®ï¼Œä½¿ç”¨æœ€æ–°çš„24å°æ—¶æ•°æ®ï¼ˆæ¼”ç¤º/å›æµ‹æ¨¡å¼ï¼‰
            prediction_mode = "backtest"
            logger.warning("  âš ï¸  æ²¡æœ‰æœªæ¥æ•°æ®ï¼Œåˆ‡æ¢åˆ°æ¼”ç¤º/å›æµ‹æ¨¡å¼")
            logger.info("  ğŸ’¡ ä½¿ç”¨æœ€æ–°çš„24å°æ—¶å†å²æ•°æ®æ¥å±•ç¤ºæ¨¡å‹é¢„æµ‹èƒ½åŠ›")
            logger.info("  ğŸ’¡ è‹¥è¦çœŸå®é¢„æµ‹ï¼Œè¯·å…ˆè¿è¡Œ: python pipelines/2_daily_feature_pipeline.py")
            
            # ä½¿ç”¨æœ€æ–°çš„24æ¡è®°å½•
            df = df.tail(24).copy()
            logger.info(f"  âœ… ä½¿ç”¨æœ€æ–°å†å²æ•°æ®: {len(df)} æ¡ï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰")
        
        # 4. åŠ è½½æ¨¡å‹
        logger.info("æ­¥éª¤ 4/6: åŠ è½½æ¨¡å‹...")
        
        model_path = f"models/{MODEL_NAME}.pkl"
        
        if not os.path.exists(model_path):
            # å°è¯•ä»Hopsworksä¸‹è½½
            logger.info("  æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨,ä»Hopsworksä¸‹è½½...")
            mr = fsm.get_model_registry()
            model_obj = mr.get_model(MODEL_NAME, version=1)
            model_dir = model_obj.download()
            model_path = os.path.join(model_dir, f"{MODEL_NAME}.pkl")
        
        model = ElectricityPriceModel()
        model.load_model(model_path)
        
        # 5. æ•°æ®æ¸…ç†å’Œé¢„æµ‹
        logger.info("æ­¥éª¤ 5/6: æ•°æ®æ¸…ç†å’Œæ‰§è¡Œé¢„æµ‹...")
        
        # ä¿å­˜ timestamp ç”¨äºç»“æœ
        timestamps = df['timestamp'].copy()
        
        # ç§»é™¤éæ•°å€¼åˆ—
        exclude_cols = ['timestamp']
        cols_to_drop = [col for col in df.columns if col in exclude_cols or df[col].dtype == 'object']
        
        if cols_to_drop:
            logger.info(f"  ç§»é™¤åˆ—: {cols_to_drop}")
            df_clean = df.drop(columns=cols_to_drop)
        else:
            df_clean = df.copy()
        
        # å‡†å¤‡é¢„æµ‹æ•°æ®ï¼ˆç¡®ä¿ç‰¹å¾é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        feature_cols = model.feature_names
        
        # æ£€æŸ¥ç¼ºå¤±çš„ç‰¹å¾
        missing_features = set(feature_cols) - set(df_clean.columns)
        if missing_features:
            logger.warning(f"  âš ï¸  ç¼ºå¤±ç‰¹å¾: {missing_features}")
            logger.warning("  å°†ç”¨0å¡«å……ç¼ºå¤±ç‰¹å¾")
            for feat in missing_features:
                df_clean[feat] = 0
        
        X_pred = df_clean[feature_cols].fillna(0)
        logger.info(f"  âœ… é¢„æµ‹ç‰¹å¾: {len(feature_cols)} ä¸ª")
        
        # æ‰§è¡Œé¢„æµ‹
        predictions = model.predict(X_pred)
        logger.info(f"  âœ… å®Œæˆ {len(predictions)} ä¸ªé¢„æµ‹")
        
        # åˆ›å»ºé¢„æµ‹ç»“æœDataFrame
        results_df = pd.DataFrame({
            'timestamp': timestamps,
            'predicted_price': predictions,
            'mode': prediction_mode  # æ·»åŠ æ¨¡å¼æ ‡è¯†
        })
        
        # å¦‚æœæœ‰å®é™…ä»·æ ¼,æ·»åŠ å¯¹æ¯”
        if 'price' in df.columns:
            results_df['actual_price'] = df['price'].values
            results_df['error'] = results_df['actual_price'] - results_df['predicted_price']
            results_df['abs_error'] = np.abs(results_df['error'])
        
        mode_name = "çœŸå®é¢„æµ‹" if prediction_mode == "forecast" else "æ¼”ç¤º/å›æµ‹"
        logger.info(f"  âœ… é¢„æµ‹äº† {len(results_df)} ä¸ªå°æ—¶çš„ç”µä»·ï¼ˆ{mode_name}æ¨¡å¼ï¼‰")
        
        # 6. ä¿å­˜é¢„æµ‹ç»“æœ
        logger.info("æ­¥éª¤ 6/6: ä¿å­˜é¢„æµ‹ç»“æœ...")
        
        # ä¿å­˜ä¸ºJSON(ä¾›UIä½¿ç”¨)
        output_dir = "predictions"
        os.makedirs(output_dir, exist_ok=True)
        
        output_file = os.path.join(
            output_dir, 
            f"predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        
        # è½¬æ¢ä¸ºJSONæ ¼å¼
        results_json = results_df.to_dict(orient='records')
        
        with open(output_file, 'w') as f:
            json.dump(results_json, f, indent=2, default=str)
        
        # åŒæ—¶ä¿å­˜æœ€æ–°é¢„æµ‹(è¦†ç›–)
        latest_file = os.path.join(output_dir, "latest_predictions.json")
        with open(latest_file, 'w') as f:
            json.dump(results_json, f, indent=2, default=str)
        
        logger.info(f"  âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        logger.info(f"  âœ… æœ€æ–°é¢„æµ‹: {latest_file}")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        logger.info(f"\n{'='*70}")
        logger.info(f"ğŸ“Š é¢„æµ‹ç»Ÿè®¡ ({mode_name}æ¨¡å¼)")
        logger.info(f"{'='*70}")
        logger.info(f"  é¢„æµ‹æ¨¡å¼: {mode_name}")
        logger.info(f"  é¢„æµ‹æ—¶æ®µ: {len(results_df)} å°æ—¶")
        logger.info(f"  æ—¶é—´èŒƒå›´: {results_df['timestamp'].min()} åˆ° {results_df['timestamp'].max()}")
        logger.info(f"  å¹³å‡é¢„æµ‹ä»·æ ¼: {results_df['predicted_price'].mean():.2f} EUR/MWh")
        logger.info(f"  æœ€ä½é¢„æµ‹ä»·æ ¼: {results_df['predicted_price'].min():.2f} EUR/MWh")
        logger.info(f"  æœ€é«˜é¢„æµ‹ä»·æ ¼: {results_df['predicted_price'].max():.2f} EUR/MWh")
        
        if 'actual_price' in results_df.columns:
            mae = results_df['abs_error'].mean()
            logger.info(f"  âœ… MAEï¼ˆä¸å®é™…ä»·æ ¼å¯¹æ¯”ï¼‰: {mae:.2f} EUR/MWh")
        
        # æ‰¾åˆ°æœ€ä¾¿å®œçš„4å°æ—¶æ—¶æ®µ(ç”¨äº"æ´—è¡£è®¡æ—¶å™¨")
        logger.info(f"\nğŸ’¡ æœ€ä¾¿å®œçš„4å°æ—¶ï¼ˆæ¨èç”¨ç”µæ—¶æ®µï¼‰:")
        cheapest_hours = results_df.nsmallest(4, 'predicted_price')
        for _, row in cheapest_hours.iterrows():
            logger.info(f"  ğŸ• {row['timestamp']}: {row['predicted_price']:.2f} EUR/MWh")
        
        logger.info(f"\n{'='*70}")
        logger.info("âœ… æ¨ç†å®Œæˆ!")
        logger.info(f"{'='*70}\n")
        
        return True
        
    except Exception as e:
        logger.error(f"\n{'='*70}")
        logger.error("âŒ æ¨ç†å¤±è´¥!")
        logger.error(f"é”™è¯¯ä¿¡æ¯: {e}")
        logger.error(f"{'='*70}\n")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    success = run_inference()
    
    if success:
        logger.info("æ¨ç†ç®¡é“æ‰§è¡ŒæˆåŠŸ")
        exit(0)
    else:
        logger.error("æ¨ç†ç®¡é“æ‰§è¡Œå¤±è´¥")
        exit(1)


if __name__ == "__main__":
    main()

